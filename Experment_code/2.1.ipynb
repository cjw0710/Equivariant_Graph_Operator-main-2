{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class E_GCL(nn.Module):\n",
    "    \"\"\"\n",
    "    E(n) Equivariant Convolutional Layer\n",
    "    re\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_nf, output_nf, hidden_nf, edges_in_d=0, act_fn=nn.SiLU(), residual=True, attention=False, normalize=False, coords_agg='mean', tanh=False):\n",
    "        super(E_GCL, self).__init__()\n",
    "        input_edge = input_nf * 2\n",
    "        self.residual = residual\n",
    "        self.attention = attention\n",
    "        self.normalize = normalize\n",
    "        self.coords_agg = coords_agg\n",
    "        self.tanh = tanh\n",
    "        self.epsilon = 1e-8\n",
    "        edge_coords_nf = 1\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(input_edge + edge_coords_nf + edges_in_d, hidden_nf),\n",
    "            act_fn,\n",
    "            nn.Linear(hidden_nf, hidden_nf),\n",
    "            act_fn)\n",
    "\n",
    "        self.node_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_nf + input_nf, hidden_nf),\n",
    "            act_fn,\n",
    "            nn.Linear(hidden_nf, output_nf))\n",
    "\n",
    "        layer = nn.Linear(hidden_nf, 1, bias=False)\n",
    "        torch.nn.init.xavier_uniform_(layer.weight, gain=0.001)\n",
    "\n",
    "        coord_mlp = []\n",
    "        coord_mlp.append(nn.Linear(hidden_nf, hidden_nf))\n",
    "        coord_mlp.append(act_fn)\n",
    "        coord_mlp.append(layer)\n",
    "        if self.tanh:\n",
    "            coord_mlp.append(nn.Tanh())\n",
    "        self.coord_mlp = nn.Sequential(*coord_mlp)\n",
    "\n",
    "        if self.attention:\n",
    "            self.att_mlp = nn.Sequential(\n",
    "                nn.Linear(hidden_nf, 1),\n",
    "                nn.Sigmoid())\n",
    "\n",
    "    def edge_model(self, source, target, radial, edge_attr):\n",
    "        if edge_attr is None:  # Unused.\n",
    "            out = torch.cat([source, target, radial], dim=1)\n",
    "        else:\n",
    "            out = torch.cat([source, target, radial, edge_attr], dim=1)\n",
    "        out = self.edge_mlp(out)\n",
    "        if self.attention:\n",
    "            att_val = self.att_mlp(out)\n",
    "            out = out * att_val\n",
    "        return out\n",
    "\n",
    "    def node_model(self, x, edge_index, edge_attr, node_attr):\n",
    "        row, col = edge_index\n",
    "        agg = unsorted_segment_sum(edge_attr, row, num_segments=x.size(0))\n",
    "        if node_attr is not None:\n",
    "            agg = torch.cat([x, agg, node_attr], dim=1)\n",
    "        else:\n",
    "            agg = torch.cat([x, agg], dim=1)\n",
    "        out = self.node_mlp(agg)\n",
    "        if self.residual:\n",
    "            out = x + out\n",
    "        return out, agg\n",
    "\n",
    "    def coord_model(self, coord, edge_index, coord_diff, edge_feat):\n",
    "        row, col = edge_index\n",
    "        trans = coord_diff * self.coord_mlp(edge_feat)\n",
    "        if self.coords_agg == 'sum':\n",
    "            agg = unsorted_segment_sum(trans, row, num_segments=coord.size(0))\n",
    "        elif self.coords_agg == 'mean':\n",
    "            agg = unsorted_segment_mean(trans, row, num_segments=coord.size(0))\n",
    "        else:\n",
    "            raise Exception('Wrong coords_agg parameter' % self.coords_agg)\n",
    "        coord = coord + agg\n",
    "        return coord\n",
    "\n",
    "    def coord2radial(self, edge_index, coord):\n",
    "        row, col = edge_index\n",
    "        coord_diff = coord[row] - coord[col]\n",
    "        radial = torch.sum(coord_diff**2, 1).unsqueeze(1)\n",
    "\n",
    "        if self.normalize:\n",
    "            norm = torch.sqrt(radial).detach() + self.epsilon\n",
    "            coord_diff = coord_diff / norm\n",
    "\n",
    "        return radial, coord_diff\n",
    "\n",
    "    def forward(self, h, edge_index, coord, edge_attr=None, node_attr=None):\n",
    "        row, col = edge_index\n",
    "        radial, coord_diff = self.coord2radial(edge_index, coord)\n",
    "\n",
    "        edge_feat = self.edge_model(h[row], h[col], radial, edge_attr)\n",
    "        coord = self.coord_model(coord, edge_index, coord_diff, edge_feat)\n",
    "        h, agg = self.node_model(h, edge_index, edge_feat, node_attr)\n",
    "\n",
    "        return h, coord, edge_attr\n",
    "\n",
    "\n",
    "class EGNN(nn.Module):\n",
    "    def __init__(self, in_node_nf, hidden_nf, out_node_nf, in_edge_nf=0, device='cpu', act_fn=nn.SiLU(), n_layers=4, residual=True, attention=False, normalize=False, tanh=False):\n",
    "        '''\n",
    "\n",
    "        :param in_node_nf: Number of features for 'h' at the input\n",
    "        :param hidden_nf: Number of hidden features\n",
    "        :param out_node_nf: Number of features for 'h' at the output\n",
    "        :param in_edge_nf: Number of features for the edge features\n",
    "        :param device: Device (e.g. 'cpu', 'cuda:0',...)\n",
    "        :param act_fn: Non-linearity\n",
    "        :param n_layers: Number of layer for the EGNN\n",
    "        :param residual: Use residual connections, we recommend not changing this one\n",
    "        :param attention: Whether using attention or not\n",
    "        :param normalize: Normalizes the coordinates messages such that:\n",
    "                    instead of: x^{l+1}_i = x^{l}_i + Σ(x_i - x_j)phi_x(m_ij)\n",
    "                    we get:     x^{l+1}_i = x^{l}_i + Σ(x_i - x_j)phi_x(m_ij)/||x_i - x_j||\n",
    "                    We noticed it may help in the stability or generalization in some future works.\n",
    "                    We didn't use it in our paper.\n",
    "        :param tanh: Sets a tanh activation function at the output of phi_x(m_ij). I.e. it bounds the output of\n",
    "                        phi_x(m_ij) which definitely improves in stability but it may decrease in accuracy.\n",
    "                        We didn't use it in our paper.\n",
    "        '''\n",
    "\n",
    "        super(EGNN, self).__init__()\n",
    "        self.hidden_nf = hidden_nf\n",
    "        self.device = device\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding_in = nn.Linear(in_node_nf, self.hidden_nf)\n",
    "        self.embedding_out = nn.Linear(self.hidden_nf, out_node_nf)\n",
    "        for i in range(0, n_layers):\n",
    "            self.add_module(\"gcl_%d\" % i, E_GCL(self.hidden_nf, self.hidden_nf, self.hidden_nf, edges_in_d=in_edge_nf,\n",
    "                                                act_fn=act_fn, residual=residual, attention=attention,\n",
    "                                                normalize=normalize, tanh=tanh))\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, h, x, edges, edge_attr):\n",
    "        h = self.embedding_in(h)\n",
    "        for i in range(0, self.n_layers):\n",
    "            h, x, _ = self._modules[\"gcl_%d\" % i](h, edges, x, edge_attr=edge_attr)\n",
    "        h = self.embedding_out(h)\n",
    "        return h, x\n",
    "\n",
    "\n",
    "def unsorted_segment_sum(data, segment_ids, num_segments):\n",
    "    result_shape = (num_segments, data.size(1))\n",
    "    result = data.new_full(result_shape, 0)  # Init empty result tensor.\n",
    "    segment_ids = segment_ids.unsqueeze(-1).expand(-1, data.size(1))\n",
    "    result.scatter_add_(0, segment_ids, data)\n",
    "    return result\n",
    "\n",
    "\n",
    "def unsorted_segment_mean(data, segment_ids, num_segments):\n",
    "    result_shape = (num_segments, data.size(1))\n",
    "    segment_ids = segment_ids.unsqueeze(-1).expand(-1, data.size(1))\n",
    "    result = data.new_full(result_shape, 0)  # Init empty result tensor.\n",
    "    count = data.new_full(result_shape, 0)\n",
    "    result.scatter_add_(0, segment_ids, data)\n",
    "    count.scatter_add_(0, segment_ids, torch.ones_like(data))\n",
    "    return result / count.clamp(min=1)\n",
    "\n",
    "\n",
    "def get_edges(n_nodes):\n",
    "    rows, cols = [], []\n",
    "    for i in range(n_nodes):\n",
    "        for j in range(n_nodes):\n",
    "            if i != j:\n",
    "                rows.append(i)\n",
    "                cols.append(j)\n",
    "\n",
    "    edges = [rows, cols]\n",
    "    return edges\n",
    "\n",
    "\n",
    "def get_edges_batch(n_nodes, batch_size):\n",
    "    edges = get_edges(n_nodes)\n",
    "    edge_attr = torch.ones(len(edges[0]) * batch_size, 1)\n",
    "    edges = [torch.LongTensor(edges[0]), torch.LongTensor(edges[1])]\n",
    "    if batch_size == 1:\n",
    "        return edges, edge_attr\n",
    "    elif batch_size > 1:\n",
    "        rows, cols = [], []\n",
    "        for i in range(batch_size):\n",
    "            rows.append(edges[0] + n_nodes * i)\n",
    "            cols.append(edges[1] + n_nodes * i)\n",
    "        edges = [torch.cat(rows), torch.cat(cols)]\n",
    "    return edges, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1]) torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "# Dummy parameters\n",
    "batch_size = 8\n",
    "n_nodes = 4\n",
    "n_feat = 1\n",
    "x_dim = 3\n",
    "\n",
    "# Dummy variables h, x and fully connected edges\n",
    "h = torch.ones(batch_size *  n_nodes, n_feat)\n",
    "x = torch.ones(batch_size * n_nodes, x_dim)\n",
    "edges, edge_attr = get_edges_batch(n_nodes, batch_size)\n",
    "\n",
    "# Initialize EGNN\n",
    "egnn = EGNN(in_node_nf=n_feat, hidden_nf=32, out_node_nf=1, in_edge_nf=1)\n",
    "\n",
    "# Run EGNN\n",
    "h, x = egnn(h, x, edges, edge_attr)\n",
    "print(h.shape, x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "等变性（equivariance）在这里指的是，对输入进行某种变换（在这里是旋转），然后再通过模型进行计算，应该与先通过模型计算再对输出进行同样的变换达到相同的效果。这是等变性的基本定义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1\n",
      " tensor([[ 0.2468,  0.1668,  0.1170],\n",
      "        [ 0.0284, -0.2837,  0.3107],\n",
      "        [ 0.1274, -0.3473,  0.0111]], grad_fn=<AddmmBackward0>)\n",
      "h1 @ rot\n",
      " tensor([[-0.2770, -0.1512, -0.0527],\n",
      "        [-0.0427, -0.0411,  0.4176],\n",
      "        [-0.0907,  0.2395,  0.2672]], grad_fn=<MmBackward0>)\n",
      "h_rot\n",
      " tensor([[ 0.2468,  0.1668,  0.1170],\n",
      "        [ 0.0284, -0.2837,  0.3107],\n",
      "        [ 0.1274, -0.3473,  0.0111]], grad_fn=<AddmmBackward0>)\n",
      "x1\n",
      " tensor([[ 1.7827, -2.1261, -0.3752],\n",
      "        [ 0.0618, -0.0388,  0.8294],\n",
      "        [ 0.6664, -0.6590,  0.0346]], grad_fn=<AddBackward0>)\n",
      "x1 @ rot\n",
      " tensor([[-1.4786,  1.9711,  1.3295],\n",
      "        [-0.1753, -0.5781,  0.5729],\n",
      "        [-0.5920,  0.5193,  0.5095]], grad_fn=<MmBackward0>)\n",
      "x_rot\n",
      " tensor([[-1.4786,  1.9711,  1.3295],\n",
      "        [-0.1753, -0.5781,  0.5729],\n",
      "        [-0.5920,  0.5193,  0.5095]], grad_fn=<AddBackward0>)\n",
      "Are h1 @ rot and h_rot close? False\n",
      "Are x1 @ rot and x_rot close? True\n"
     ]
    }
   ],
   "source": [
    "from e3nn import o3\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 假设你的 EGNN 类和 get_edges_batch 函数已经定义\n",
    "# from your_egnn_module import EGNN, get_edges_batch\n",
    "\n",
    "# 随机生成旋转矩阵\n",
    "rot = o3.rand_matrix()\n",
    "\n",
    "# 初始化虚拟变量\n",
    "batch_size = 1\n",
    "n_nodes = 3\n",
    "n_feat = 3\n",
    "x_dim = 3\n",
    "h = torch.randn(batch_size *  n_nodes, n_feat)\n",
    "x = torch.randn(batch_size * n_nodes, x_dim)\n",
    "edges, edge_attr = get_edges_batch(n_nodes, batch_size)\n",
    "\n",
    "# 初始化 EGNN\n",
    "egnn = EGNN(in_node_nf=n_feat, hidden_nf=32, out_node_nf=3, in_edge_nf=1)\n",
    "\n",
    "# 测试等变性\n",
    "# 先传递通过模型\n",
    "h1, x1 = egnn(h, x, edges, edge_attr)\n",
    "\n",
    "# 旋转并传递通过模型\n",
    "h_rot, x_rot = egnn(h, x @ rot, edges, edge_attr)\n",
    "\n",
    "# 旋转模型的初始输出\n",
    "h1_rot = h1 @ rot\n",
    "x1_rot = x1 @ rot\n",
    "\n",
    "# 检查网络是否等变\n",
    "print(\"h1\\n\", h1)\n",
    "print(\"h1 @ rot\\n\", h1_rot)\n",
    "print(\"h_rot\\n\", h_rot)\n",
    "\n",
    "print(\"x1\\n\", x1)\n",
    "print(\"x1 @ rot\\n\", x1_rot)\n",
    "print(\"x_rot\\n\", x_rot)\n",
    "\n",
    "print(\"Are h1 @ rot and h_rot close?\", torch.allclose(h1_rot, h_rot, atol=1e-6))\n",
    "print(\"Are x1 @ rot and x_rot close?\", torch.allclose(x1_rot, x_rot, atol=1e-6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
